{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a81f69",
   "metadata": {},
   "source": [
    "# 데이터 전처리 알고리즘\n",
    "- 본 연구는 2019년 라이프로그 데이터를 대상으로 연구 및 실험 진행\n",
    "- 데이터 구성은 아래와 같음\n",
    "    - 유저명 디렉토리 \n",
    "        - 타임스탬프 디렉토리 \n",
    "            - 유저 라벨 정보.csv\n",
    "            - 타임스탬프에서 측정된 센서값이 있는 디렉토리\n",
    "                - 타임스탬프 별 센서 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856e247",
   "metadata": {},
   "source": [
    "## User별 Time-Series data 전처리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592dd7bc",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a44962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import re \n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4d77c",
   "metadata": {},
   "source": [
    "### 시간대 별 특징을 추출하기 위한 함수 정의\n",
    "\n",
    "1초 기준으로 Max값을 추출하여 정리하였음\n",
    "무분별한 시간대 정리, 통일화. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def group_sec(data , freq):\n",
    "    \n",
    "    data['datetime'] =  pd.to_datetime(data['timestamp'], unit='s')\n",
    "    \n",
    "                \n",
    "    #data['datetime'] = pd.to_timedelta(data['timestamp'], unit='s')\n",
    "    df = data.set_index('datetime')\n",
    "    \n",
    "    ten_sec_df = df.groupby(pd.Grouper(freq=freq)).agg('max')\n",
    "    ten_sec_df = ten_sec_df.interpolate()\n",
    "\n",
    "    ten_sec_df = ten_sec_df.reset_index()\n",
    "    return ten_sec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f82da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_pre_dir = '/workspace/data/dataset_2019/'\n",
    "for d in os.listdir(pre_pre_dir):\n",
    "\n",
    "    pre_dir = pre_pre_dir + d +\"/\"\n",
    "    lst_timestamp = os.listdir(pre_dir)\n",
    "    # print(d)\n",
    "\n",
    "    for ts in lst_timestamp:\n",
    "        time_pre_dir = pre_dir + ts + '/'\n",
    "        for ma in os.listdir(time_pre_dir):\n",
    "            if ma[-4] == '.':\n",
    "                continue\n",
    "            t = time_pre_dir+ma+'/'\n",
    "            df = pd.DataFrame()\n",
    "            for detail_timestamp in os.listdir(t):\n",
    "                file_dir = t + detail_timestamp\n",
    "\n",
    "                tmp_data = pd.read_csv(file_dir)\n",
    "                tmp_data['timestamp'] += int(detail_timestamp.replace('.csv',''))\n",
    "\n",
    "                tmp_data = group_sec(tmp_data,'5s')\n",
    "                tmp_data.rename(columns = lambda x: ma +\"__\"+ x, inplace = True)\n",
    "\n",
    "                #print(tmp_data.shape)\n",
    "                df = pd.concat([df,tmp_data],ignore_index=True)\n",
    "            df.to_csv(time_pre_dir+ma+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fce5f",
   "metadata": {},
   "source": [
    "### 전처리한 데이터를 바탕으로 모델에 맞는 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "ppre_dir = '/workspace/data/dataset_2019/'\n",
    "\n",
    "for filename in os.listdir(ppre_dir):\n",
    "    \n",
    "    _pre_dir = ppre_dir + filename+'/'\n",
    "    df = pd.DataFrame()\n",
    "    # print(_pre_dir)\n",
    "    for d in os.listdir(_pre_dir):\n",
    "        cnt = 0 \n",
    "        pre_dir = _pre_dir + d + '/'\n",
    "        check = False\n",
    "        for file in os.listdir(pre_dir):\n",
    "            if  ('.' not in file )or ('label' in file ):\n",
    "                continue\n",
    "            #print(file)\n",
    "            if cnt == 0 :\n",
    "                cnt +=1 \n",
    "                t_df = pd.read_csv(pre_dir + file,index_col=0)\n",
    "                if t_df.shape[0] <= 0 :\n",
    "                    break\n",
    "                t_df.rename(columns={ file.replace('.csv','')+'__datetime':'datetime'}, inplace = True)\n",
    "\n",
    "                t_df['datetime'] = pd.to_datetime(t_df['datetime']).astype(str)\n",
    "                t_df =t_df.drop(columns = [file.replace('.csv','')+'__timestamp'])\n",
    "                #e4Acc__timestamp\n",
    "                continue\n",
    "            tmp_df = pd.read_csv(pre_dir + file,index_col=0)\n",
    "            if tmp_df.shape[0] <= 0 :\n",
    "                break        \n",
    "            word = file.replace('.csv','')+'__timestamp'\n",
    "            tmp_df =tmp_df.drop(columns = [file.replace('.csv','')+'__timestamp'])\n",
    "\n",
    "            tmp_df.rename(columns={ file.replace('.csv','')+'__datetime':'datetime'}, inplace = True)\n",
    "            tmp_df['datetime'] = pd.to_datetime(tmp_df['datetime']).astype(str)\n",
    "            t_df = pd.merge(t_df, tmp_df, on=['datetime'], how = 'inner')\n",
    "        df = pd.concat([df,t_df])\n",
    "    df = df.set_index(['datetime'])\n",
    "    df = df.sort_index()\n",
    "    lst = os.listdir(_pre_dir)\n",
    "    concat_label = pd.DataFrame()\n",
    "    for f in lst:\n",
    "        \n",
    "        file_path = f'{_pre_dir}{f}/{f}_label.csv'\n",
    "        label = pd.read_csv(file_path)\n",
    "        if label.shape[0] <= 0 :\n",
    "            continue\n",
    "        label['datetime'] =  pd.to_datetime(label['ts'], unit='s')\n",
    "\n",
    "        label = label.set_index(['datetime'])\n",
    "        label = label[~label.index.duplicated()]\n",
    "        label_5s = label.resample('5s').ffill()\n",
    "\n",
    "        concat_label = pd.concat([concat_label,label_5s])\n",
    "    concat_label = concat_label.sort_index()\n",
    "    concat_label = concat_label.drop(columns = ['ts'])\n",
    "    df = df.reset_index()\n",
    "    concat_label = concat_label.reset_index()\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    concat_label['datetime'] = pd.to_datetime(concat_label['datetime'])\n",
    "    merged_df = pd.merge(df, concat_label, on='datetime', how='inner')\n",
    "    merged_df.fillna(0)\n",
    "    merged_df = merged_df.set_index('datetime')\n",
    "    merged_df.to_csv(f'processed_data/tmp_merged_{filename}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81692d82",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec73216",
   "metadata": {},
   "source": [
    "### 2019년 사용자 개인정보 파일 로드\n",
    "- 이전 과정에서 전처리한 데이터를 Load\n",
    "- 필요한 2019년 사용자의 정보만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b94960",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>startDt</th>\n",
       "      <th>endDt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>161.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>161.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>2019-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>171.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>165.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>2019-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>167.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>2019-12-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  age  height  weight     startDt       endDt\n",
       "userId                                                    \n",
       "101         F   23   161.0    52.0  2020-01-01  2020-01-13\n",
       "102         F   22   161.0    50.0  2019-12-09  2019-12-23\n",
       "103         F   19   171.0    61.0  2020-01-04  2020-01-16\n",
       "104         F   24   165.0    52.0  2019-12-04  2019-12-23\n",
       "105         F   19   167.0    68.0  2019-12-04  2019-12-19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_info_2019_2018_updated.csv가 있는 경로를 설정\n",
    "user_info_df = pd.read_csv('data_dir')\n",
    "user_info_df.set_index('userId', inplace=True)\n",
    "user_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e927f6",
   "metadata": {},
   "source": [
    "#### Processed 된 Time-Series_data데이터를 바탕으로 Model에 맞도록 모달리티 별 차원 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e6d6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65b6920b28d4a10b0c0e7d8cdc1d3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebded17d2c1943c9bde10797ac2fab7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53123d266db74227ae45712f00826a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60c5f05e89c43ab8ea933fd03887699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cff6038538d4feaa1fe86a146d9db86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d3be6a16254047b17b2f524cccc67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a273b7ca70946cbae3d058a8766a0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a47325a44a42bf9f175970aaf24de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3f81c0db084105b897d1d95f5d3cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc361865802944b4bfcfd69168505265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34321568b6774b35859c46a2d21e5816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e6e21780ea41978802caed978b56c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c070c11ce714b099a58aa7318a4ee45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273d1639197c4c25b4a1d979a6ee4798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c07b200a58f4f7daeeb7999ea0415aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a15343636b49108f11de8eaac59bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edc6758ef8746e48269b22ba9f3744a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4672731df6204696ada561a23a36cf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc3e5ce3dc3433f80b726b2a59c2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce48087eca734a1dbda322a78a14e1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d461435608e04517bab285643b49c26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for user_name in tqdm_notebook(list(user_info_df.index[:20])):\n",
    "    # 2019년 유저 데이터가 있는 파일 경ㄹ\n",
    "    dataset_path = '/workspace/data/processed_data/'\n",
    "    temp_user_path = dataset_path + user_name + '/'\n",
    "\n",
    "    temp_user_labels = os.listdir(temp_user_path)\n",
    "\n",
    "    prpDf = pd.concat([pd.read_csv(temp_user_path + temp_user_labels[j] + '/' + temp_user_labels[j] + '_label.csv') for j in range(len(temp_user_labels))], 0)\n",
    "\n",
    "    prpDf.reset_index(inplace=True)\n",
    "\n",
    "    prpDf['userName'] = [user_name for j in range(len(prpDf))]\n",
    "\n",
    "    prpDf['gender'] = [user_info_df['gender'][prpDf['userName'][j]] for j in range(len(prpDf))]\n",
    "    prpDf['height'] = [user_info_df['height'][prpDf['userName'][j]] for j in range(len(prpDf))]\n",
    "    prpDf['weight'] = [user_info_df['weight'][prpDf['userName'][j]] for j in range(len(prpDf))]\n",
    "\n",
    "    prpDf = prpDf[['userName', 'ts', 'emotionPositive', 'emotionTension', 'action', 'gender', 'height', 'weight']]\n",
    "\n",
    "    prpDf['e4Acc'] = [[] for j in range(len(prpDf))]\n",
    "    prpDf['e4Bvp'] = [np.array([]) for j in range(len(prpDf))]\n",
    "    prpDf['e4Eda'] = [np.array([]) for j in range(len(prpDf))]\n",
    "    prpDf['e4Hr'] = [np.array([]) for j in range(len(prpDf))]\n",
    "    prpDf['e4Temp'] = [np.array([]) for j in range(len(prpDf))]\n",
    "\n",
    "    prpDf['mAcc'] = [[] for j in range(len(prpDf))]\n",
    "    prpDf['mGps'] = [[] for j in range(len(prpDf))]\n",
    "    prpDf['mGyr'] = [[] for j in range(len(prpDf))]\n",
    "    prpDf['mMag'] = [[] for j in range(len(prpDf))]\n",
    "\n",
    "    prpDf.set_index('ts', inplace=True)\n",
    "\n",
    "    tempE4AccDict = {}\n",
    "    for i in tqdm_notebook(range(len(temp_user_labels))):\n",
    "        e4Acc_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'e4Acc')\n",
    "        temp_datas = dict([(e4Acc[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'e4Acc/' + e4Acc).values[:, 1:]) for e4Acc in e4Acc_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['e4Acc'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        e4Bvp_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'e4Bvp')\n",
    "        temp_datas = dict([(e4Bvp[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'e4Bvp/' + e4Bvp).values[:, 1:]) for e4Bvp in e4Bvp_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['e4Bvp'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        e4Eda_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'e4Eda')\n",
    "        temp_datas = dict([(e4Eda[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'e4Eda/' + e4Eda).values[:, 1:]) for e4Eda in e4Eda_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['e4Eda'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        e4Hr_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'e4Hr')\n",
    "        temp_datas = dict([(e4Hr[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'e4Hr/' + e4Hr).values[:, 1:]) for e4Hr in e4Hr_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['e4Hr'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        e4Temp_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'e4Temp')\n",
    "        temp_datas = dict([(e4Temp[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'e4Temp/' + e4Temp).values[:, 1:]) for e4Temp in e4Temp_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['e4Temp'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        mAcc_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'mAcc')\n",
    "        temp_datas = dict([(mAcc[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'mAcc/' + mAcc).values[:, 1:]) for mAcc in mAcc_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['mAcc'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        mGps_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'mGps')\n",
    "        temp_datas = dict([(mGps[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'mGps/' + mGps).values[:, 1:]) for mGps in mGps_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['mGps'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        mGyr_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'mGyr')\n",
    "        temp_datas = dict([(mGyr[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'mGyr/' + mGyr).values[:, 1:]) for mGyr in mGyr_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['mGyr'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        mMag_temp_file = os.listdir(temp_user_path + temp_user_labels[i] + '/' + 'mMag')\n",
    "        temp_datas = dict([(mMag[:-4], pd.read_csv(temp_user_path + temp_user_labels[i] + '/' + 'mMag/' + mMag).values[:, 1:]) for mMag in mMag_temp_file])\n",
    "        for td in list(temp_datas.keys()):\n",
    "            try:\n",
    "                prpDf['mMag'][int(td)] = temp_datas[td]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    prpDf['e4AccLen'] = prpDf['e4Acc'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['e4AccLen']==0].index, 0)\n",
    "    prpDf['e4BvpLen'] = prpDf['e4Bvp'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['e4BvpLen']==0].index, 0)\n",
    "    prpDf['e4EdaLen'] = prpDf['e4Eda'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['e4EdaLen']==0].index, 0)\n",
    "    prpDf['e4HrLen'] = prpDf['e4Hr'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['e4HrLen']==0].index, 0)\n",
    "    prpDf['e4TempLen'] = prpDf['e4Temp'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['e4TempLen']==0].index, 0)\n",
    "    prpDf['mAccLen'] = prpDf['mAcc'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['mAccLen']==0].index, 0)\n",
    "    prpDf['mGpsLen'] = prpDf['mGps'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['mGpsLen']==0].index, 0)\n",
    "    prpDf['mGyrLen'] = prpDf['mGyr'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['mGyrLen']==0].index, 0)\n",
    "    prpDf['mMagLen'] = prpDf['mMag'].map(len)\n",
    "    prpDf = prpDf.drop(prpDf[prpDf['mMagLen']==0].index, 0)\n",
    "    \n",
    "    with open(user_name + '_prpDf.pickle', 'wb') as f:\n",
    "        pickle.dump(prpDf, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270b7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
